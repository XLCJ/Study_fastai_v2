
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/Datablock_Lesson5.ipynb

Path.ls = lambda x: list(x.iterdir())

# this function gets all the fnames within a given directory,
# excluding hidden files that starts with '.'
# include all files when an extension is not given
# or if extensions is given, if the given ones is within our target extension list
# NOTE: the extensions need to start with a '.', e.g. '.jpg'
def _get_files(directory, fnames, extensions=None):
    p = Path(directory)
    res = [p/f for f in fnames if not f.startswith('.')
          and ((not extensions) or f'.{f.split(".")[-1].lower()}' in extensions)]
    return res

# this function walk through all directory and return all files
def get_files(path, extensions=None, recurse=False, include=None):
    # include = None == include all
    path = Path(path) # pathlib is easier to use
    extensions = setify(extensions) # remove duplicates
    extensions = {e.lower() for e in extensions} # lowercased
    if recurse:
        res = []
        for i, (p,d,f) in enumerate(os.walk(path)): # returns (dirpath, folder names, filenames)
            # each iteration this goes a layer deeper into sub-directories
            if include is not None and i==0:
                d[:] = [o for o in d if o in include] # include some folders, not all
            else:
                d[:] = [o for o in d if not o.startswith('.')] # include all folders except the hidden ones
            res += _get_files(p,f,extensions)
        return res
    else:
        f = [o.name for o in os.scandir(path) if o.is_file()]
        return _get_files(path, f, extensions)

# apply several functions to data x and replace x in place
def compose(x, funcs, *args, order_key='_order', **kwargs):
    key = lambda o: getattr(o, order_key, 0)
    for f in sorted(listify(funcs), key=key):
        x = f(x, **kwargs)
    return x

class ItemList(ListContainer):
    def __init__(self, items, path='.', tfms=None):
        super().__init__(items) # the list of objects can be subscripted like a numpy array
        self.path, self.tfms = Path(path), tfms

    def __repr__(self):
        return f'{super().__repr__()}\nPath: {self.path}' # print out list objects and the related path

    def new(self, items, cls=None): # create a new cls-class object
        if cls is None:
            cls = self.__class__
        return cls(items, self.path, tfms=self.tfms)

    def get(self, i): # this method needs to be overloaded by subclasses to explain how to access an element
        return i

    def _get(self, i): # apply transforms to item i
        return compose(self.get(i), self.tfms)

    def __getitem__(self, idx): # apply transform and then return
        res = super().__getitem__(idx)
        if isinstance(res, list):
            return [self._get(o) for o in res]
        return self._get(res)

def get_image_extensions():
    return set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))

# for image application only
class ImageList(ItemList): # inherent ItemList methods
    @classmethod # this is to be called directly by class name
    def from_files(cls, path, extensions=None, recurse=True, include=None, **kwargs):
        if extensions is None:
            extensions = get_image_extensions()
        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)

    def get(self, fname): # overload the parent class get to show how to access elements
        return PIL.Image.open(fname)


class Transform(): _order=0

class MakeRGB(Transform):
    def __call__(self, item): return item.convert('RGB')

def make_rgb(item): return item.convert('RGB')

def split_by_func(items, f):
    mask = [f(o) for o in items]
    # `None` values will be filtered out
    f = [o for o,m in zip(items, mask) if m==False] # the False set by given criterion f
    t = [o for o,m in zip(items, mask) if m==True] # the True set
    return f, t

def grandparent_splitter(fn, valid_name='valid', train_name='train'):
    # return boolean masks for a single item split by folder name at the grandparent level of path
    gp = fn.parent.parent.name # define grandparent
    return True if gp==valid_name else False if gp==train_name else None

# usage example
#splitter = partial(grandparent_splitter, valid_name='val')

class SplitData():
    def __init__(self, train, valid): # to be init by class method
        self.train = train # this is a class object with same class as given
        self.valid = valid

    def __getattr__(self, k): #
        return getattr(self.train, k) # to be handled by the class that train object belongs to

    #This is needed if we want to pickle SplitData and be able to load it back without recursion errors
    def __setstate__(self,data):
        self.__dict__.update(data)

    def __repr__(self): return f'{self.__class__.__name__}\nTrain: {self.train}\nValid: {self.valid}\n'

    @classmethod
    def split_by_func(cls, il, f):
        lists = map(il.new, split_by_func(il.items, f)) # il needs to have a new method
        return cls(*lists) # fed into __init__
# usage example:
#sd = SplitData.split_by_func(il, splitter)

def uniqueify(x, sort=False):
    # turn a list into a list with unique elements
    # and keep the ORDER of the elements unchanged
    res = list(OrderedDict.fromkeys(x).keys()) # orderDict will only keep unique keys
    if sort: res.sort()
    return res

class Processor():
    def process(self,items): return items

class CategoryProcessor(Processor):
    def __init__(self):
        self.vocab = None

    def __call__(self, items):
        #The vocab is defined on the first use.
        if self.vocab is None: # build vocab and reverse dict
            self.vocab = uniqueify(items) # it's a list
            self.otoi = {v:k for k,v in enumerate(self.vocab)} # reverse dict
        return [self.proc1(o) for o in items] # return indices of vocab

    def proc1(self,item):
        return self.otoi[item]

    def deprocess(self,idxs):
        assert self.vocab is not None
        return [self.deproc1(i) for i in idxs]

    def deproc1(self,idx): return self.vocab[idx]


# label by parent folder name
def parent_labeler(fn): return fn.parent.name

def _label_by_func(ds, f, cls=ItemList):
    return cls([f(o) for o in ds.items], path = ds.path) # create ItemList object

class LabeledData():
    def process(self, il, proc): # use ItemList method
        # apply process proc to data and return ItemList objects
        return il.new(compose(il.items,proc))

    def __init__(self,x,y,proc_x=None,proc_y=None):
        self.x = self.process(x,proc_x)
        self.y = self.process(y,proc_y)
        self.proc_x = proc_x
        self.proc_y = proc_y

    def __repr__(self):
        return f'{self.__class__.__name__}\nx: {self.x}\ny: {self.y}\n'
    def __getitem__(self,idx):
        return self.x[idx], self.y[idx]
    def __len__(self): return len(self.x)

    def x_obj(self,idx): return self.obj(self.x, idx, self.proc_x)
    def y_obj(self,idx): return self.obj(self.y, idx, self.proc_y)

    def obj(self,items,idx,procs):
        isint = isinstance(idx,int) or (isinstance(idx,torch.LongTensor) and not idx.ndim) # int or tensor index
        item = items[idx]
        for proc in reversed(listify(procs)):
            item = proc.deproc1(item) if isint else proc.deprocess(item) # if item is a list
        return item

    @classmethod # this is the important method to use in practice
    def label_by_func(cls, il, f, proc_x=None, proc_y=None):
        return cls(il, _label_by_func(il, f), proc_x=proc_x,proc_y=proc_y)


# use the above class, take SplitData object and return SplitData object
def label_by_func(sd, f, proc_x=None, proc_y=None):
    train = LabeledData.label_by_func(sd.train, f, proc_x=proc_x, proc_y=proc_y)
    # the vocab has been built after labeling the train set
    # so the validation set will just use the exisiting labels
    valid = LabeledData.label_by_func(sd.valid, f, proc_x=proc_x, proc_y=proc_y)
    return SplitData(train,valid)

# usage example:
# ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())

class DataBunch(): # to hold all the data together, in dataloader form
    def __init__(self, train_dl, valid_dl, c_in=None, c_out=None):
        self.train_dl,self.valid_dl,self.c_in,self.c_out = train_dl,valid_dl,c_in,c_out

    @property
    def train_ds(self): return self.train_dl.dataset

    @property
    def valid_ds(self): return self.valid_dl.dataset

def databunchify(sd, bs, c_in=None, c_out=None, **kwargs):
    dls = get_dls(sd.train, sd.valid, bs, **kwargs)
    return DataBunch(*dls, c_in=c_in, c_out=c_out)

SplitData.to_databunch = databunchify

def model_summary(run, learn, data, find_all=False):
    xb,yb = get_batch(data.valid_dl, run)
    device = next(learn.model.parameters()).device#Model may not be on the GPU yet
    xb,yb = xb.to(device),yb.to(device)
    mods = find_modules(learn.model, is_lin_layer) if find_all else learn.model.children()
    f = lambda hook,mod,inp,out: print(f"{mod}\n{out.shape}\n")
    with Hooks(mods, f) as hooks: learn.model(xb)